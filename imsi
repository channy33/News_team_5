import scrapy
from daum_it.items import DaumItItem

class DaumItSpiderSpider(scrapy.Spider):
    name = "daum_it_spider"


    start_urls = ["http://news.daum.net//breakingnews/digital?regDate=20230904"]

    def parse(self, response):

        global URL

        for i in range(1,16):
            URL = response.xpath(f'//*[@id="mArticle"]/div[3]/ul/li[{i}]/div/strong/a/@href')[0].extract()
            yield scrapy.Request(URL,callback=self.parse_page_content1)
            #print(URL,i)
            # div = response.xpath(f'//*[@id="mArticle"]/div[3]/ul/li[{i}]')

            # if (URL !=[]): #i가 비어있지않다면
            #     href = div.xpath('./div/strong/a/@href')
            #     url = response.urljoin(href[0].extract())
            #     print(url)

    def parse_page_content1(self,response): #세부항목들안으로 들어가는 함수
        item = DaumItItem()

        item['Title'] = response.xpath('//*[@id="mArticle"]/div[1]/h3/text()')[0].extract()
        item['Date'] = response.xpath('//*[@id="mArticle"]/div[1]/div[1]/span[2]/span/text()')[0].extract()
        #item['수정일시']
        item['Media'] = response.xpath('//*[@id="kakaoServiceLogo"]/text()')[0].extract()
        item['Content_URL'] = URL
        item['Contents'] = response.xpath('//*[@id="mArticle"]/div[2]/div[2]/section/p/text()').getall()
        item['Pressname'] = response.xpath('//*[@id="mArticle"]/div[1]/div[1]/span[1]/text()')[0].extract()

        return item