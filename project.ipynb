{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#뉴스데이터 불러오기\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# with open('naver_data.pkl', 'rb') as f:\n",
    "#     data1 = pickle.load(f)\n",
    "#댓글 데이터 불러오기\n",
    "data2 = pd.read_csv('naver_comments_all.csv')\n",
    "data2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 그룹화\n",
    "data4 = data2.groupby('url').nunique()\n",
    "data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#벡터화\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# URL별 유니크한 user_id들을 공백으로 연결\n",
    "data3_str = data3.apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Counter Vectorization\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data3_str)\n",
    "\n",
    "# LSA (Latent Semantic Analysis)\n",
    "svd = TruncatedSVD(n_components=10)  # n_components는 잠재 변수의 수, 적절한 값을 선택해야 합니다.\n",
    "lsa_result = svd.fit_transform(X)\n",
    "\n",
    "print(lsa_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#코사인 유사도\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# LSA 결과에서 코사인 유사도 계산\n",
    "cosine_sim = cosine_similarity(lsa_result)\n",
    "\n",
    "# URL과 인덱스 매핑 딕셔너리 생성\n",
    "indices = pd.Series(range(len(data3_str.index)), index=data3_str.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기사링크 기반 추천시스템\n",
    "def recommend(url, cosine_sim=cosine_sim):\n",
    "    # 선택한 URL의 인덱스 가져오기\n",
    "    idx = indices[url]\n",
    "\n",
    "    # 모든 URL에 대해 해당 URL과의 유사도 가져오기\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # 유사도에 따라 URL들 정렬하기\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 가장 유사한 10개의 URL 가져오기 (자신 제외)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # 가장 유사한 10개의 URL 인덱스 가져오기\n",
    "    url_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # 가장 유사한 10개의 URL 반환하기\n",
    "    return data3_str.index[url_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#코사인유사도\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "# 데이터 전처리: 각 user_id별로 방문한 url들을 공백으로 연결\n",
    "df2_str_user = data2.groupby('user_id')['url'].apply(lambda x: ' '.join(x.values))\n",
    "# Counter Vectorization\n",
    "vectorizer = CountVectorizer()\n",
    "X_user = vectorizer.fit_transform(df2_str_user)\n",
    "# LSA (Latent Semantic Analysis)\n",
    "svd = TruncatedSVD(n_components=10)  # n_components는 잠재 변수의 수, 적절한 값을 선택해야 합니다.\n",
    "lsa_result_user = svd.fit_transform(X_user)\n",
    "# User ID와 인덱스 매핑 딕셔너리 생성\n",
    "indices_user = pd.Series(range(len(df2_str_user.index)), index=df2_str_user.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리: 각 URL별로 방문한 user들을 공백으로 연결\n",
    "df2_str_url = data2.groupby('url')['user_id'].apply(lambda x: ' '.join(x.values))\n",
    "# Counter Vectorization\n",
    "vectorizer = CountVectorizer()\n",
    "X_url = vectorizer.fit_transform(df2_str_url)\n",
    "# LSA (Latent Semantic Analysis)\n",
    "svd = TruncatedSVD(n_components=10)  # n_components는 잠재 변수의 수, 적절한 값을 선택해야 합니다.\n",
    "lsa_result_url = svd.fit_transform(X_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_urls_for_users(user_id):\n",
    "    # 선택된 user의 인덱스 가져오기\n",
    "    idx = indices_user[user_id]\n",
    "    # 모든 URL에 대해 해당 user와의 유사도 가져오기\n",
    "    sim_scores_url = cosine_similarity(lsa_result_user[idx].reshape(1,-1), lsa_result_url)\n",
    "    # 유사도에 따라 url 정렬하기 (내림차순)\n",
    "    sim_scores_url_sorted_indices = np.argsort(-sim_scores_url.flatten())\n",
    "    # 가장 유사한 10개의 url 가져오기\n",
    "    top_5_similar_urls_indices = sim_scores_url_sorted_indices[:5]\n",
    "    \n",
    "    return data3_str.index[top_5_similar_urls_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#출력확인\n",
    "# dict2[recommend_urls_for_users('tvRC')[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict2 = {url: title for title, url in zip(data2.title,data2.url)}\n",
    "# dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#딕셔너리 생성\n",
    "# dict1 = {name: id for id, name in zip(data2.user_id, data2.user_name)}\n",
    "dict1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#아이디를 입력받아 뉴스 추천5개op\n",
    "a = input(\"아이디를 입력하세요 : \")\n",
    "for i in range(5):\n",
    "    print(recommend_urls_for_users(dict1[a[:4] + '****'])[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = list(dict1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_all = []\n",
    "# for i in list1:\n",
    "#     user_key = i[:4] + '****'\n",
    "#     try:\n",
    "#         for j in range(5):\n",
    "#             recommended_urls = dict2[recommend_urls_for_users(dict1[user_key])[j]]\n",
    "#             list_all.append(recommended_urls)\n",
    "#     except KeyError:\n",
    "#         pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# list_all = []\n",
    "# for i in list1:\n",
    "#     user_key = i[:4] + '****'\n",
    "#     try:\n",
    "#         for j in range(5):\n",
    "#             recommended_url = dict2[recommend_urls_for_users(dict1[user_key])[j]]\n",
    "#             list_all.append(recommended_url)\n",
    "#     except KeyError:\n",
    "#         pass\n",
    "\n",
    "# df = pd.DataFrame(list_all, columns=['recommended_url'])\n",
    "# df.to_csv('output.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mecab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
